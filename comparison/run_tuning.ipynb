{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning\n",
    "\n",
    "In this notebook, the ensemble classifiers are tuned. Most of the time we only tune the number of trees. For the following cases, we also had to tune on other parameters:\n",
    "- Class Switching (Swt and SwtET): tuning the switching ratio **p_switch**.\n",
    "- Random Patches (RadP and RadPET): tuning the number of samples **max_samples** and the number of features **max_features**.\n",
    "- Vadaboost (Vad and VadET): tuning the regularization parameter **lbda**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "from utils.filter import snr\n",
    "from utils.rms_score import rms_metric\n",
    "from utils.load_classifiers import load_classifiers_names, load_classifiers, load_grid_parameters\n",
    "from utils.load_dataset import load_big_datasets_names, load_small_datasets_names, load_datasets_names\n",
    "\n",
    "from sklearn.cross_validation import train_test_split, KFold, LeaveOneOut, StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers names:  ['AdET', 'AdSt', 'Ad', 'RadPET', 'BagET', 'ArcX4', 'ET', 'VadET', 'SwtET', 'Vad', 'ArcX4ET', 'Bag', 'RF', 'LogB', 'CART', 'RadP', 'RotET', 'RotbET', 'Rotb', 'Rot', 'Swt'] \n",
      "\n",
      "Datasets names:  ['musk', 'relathe', 'madelon', 'pcmac', 'promoters', 'spam', 'leukemia', 'parkinson', 'ovarian', 'wpbc', 'ionosphere', 'basehock', 'breast_cancer', 'colon', 'pima', 'cleve', 'wdbc', 'spect', 'smk_can']\n"
     ]
    }
   ],
   "source": [
    "## Load the names of all classifiers and datasets\n",
    "clf_names = load_classifiers_names()\n",
    "data_names = load_datasets_names()\n",
    "small_data = load_small_datasets_names()\n",
    "big_data = load_big_datasets_names()\n",
    "\n",
    "print \"Classifiers names: \", clf_names, \"\\n\"\n",
    "print \"Datasets names: \", data_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "All the datasets are stored in a HDFS file for a convinient access. To get this, go click on this [link](https://s3-eu-west-1.amazonaws.com/ensemble-comparison-data/datasets.h5) and store it in the data folder.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "datasets = pd.HDFStore(\"../data/datasets.h5\")\n",
    "# get the basehock dataset\n",
    "X = datasets['basehock_data']\n",
    "y = datasets['basehock_target']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load all the datasets\n",
    "datasets = pd.HDFStore(\"../data/datasets.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the 1-rms metric (not originally in scikit-learn)\n",
    "rms = rms_metric()\n",
    "results_path = \"./results/tuning/\"\n",
    "\n",
    "# Define a random seed for tuning (then the experiment is reproducible)\n",
    "tuning_seed = 0\n",
    "\n",
    "for clf_name in clf_names:\n",
    "    # Load the classifier and its grid parameters\n",
    "    clf = load_classifiers(clf_name)\n",
    "    grid_params = load_grid_parameters(clf_name)\n",
    " \n",
    "    print \"===== Tuning classifier %s =====\" % clf_name\n",
    "    clf_path = results_path + clf_name\n",
    "    \n",
    "    # Create a directory to store the tuning results (in pickle format)\n",
    "    if clf_name not in os.listdir(results_path):\n",
    "        os.mkdir(clf_path)\n",
    "    \n",
    "    for data_name in data_names:\n",
    "        print \"===== Tuning %s ===== on %s\" % (clf_name, data_name)\n",
    "        result_tuning = {}\n",
    "        \n",
    "        result_tuning[\"classifier_name\"] = clf_name\n",
    "        result_tuning[\"dataset_name\"] = data_name\n",
    "        result_tuning[\"validation_seed\"] = tuning_seed\n",
    "    \n",
    "        data_path = clf_path + \"/\" + data_name\n",
    "        if data_name not in os.listdir(clf_path):\n",
    "            os.mkdir(data_path)            \n",
    "        X = datasets[data_name + '_data']\n",
    "        y = datasets[data_name + '_target']\n",
    "        \n",
    "        # feature selection\n",
    "        best_features = snr(X, y) #???\n",
    "        \n",
    "        # repeat the experiment with and without feature selection when the dataset is big\n",
    "        for fs in (False, True):\n",
    "            if not fs and (not clf_name.startswith(\"Rot\") or data_name in small_data): \n",
    "                result_tuning[\"feature_selection\"] = fs\n",
    "                \n",
    "                X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=tuning_seed, stratify=y)\n",
    "                   \n",
    "                no_fs_path = data_path + '/' + \"noFS\"\n",
    "                if \"noFS\" not in os.listdir(data_path):\n",
    "                    os.mkdir(no_fs_path)\n",
    "                \n",
    "                gs_seed = 1\n",
    "                result_tuning[\"gs_seed\"] = gs_seed\n",
    "                \n",
    "                kf = StratifiedKFold(y_val, n_folds=3, shuffle=True, random_state=gs_seed)\n",
    "                \n",
    "                # Number of jobs - run the grid search in parallel.\n",
    "                n_jobs = 1\n",
    "                    \n",
    "                grid_params = load_grid_parameters(clf_name)\n",
    "                if clf_name.startswith('Swt') and data_name == \"leukemia\":\n",
    "                    grid_params['p_switch'] = np.arange(0.1, 0.25, 0.05)\n",
    "                    \n",
    "                gs_acc = GridSearchCV(clf, grid_params, scoring=\"accuracy\", n_jobs=n_jobs, cv=kf)\n",
    "                gs_auc = GridSearchCV(clf, grid_params, scoring=\"roc_auc\", n_jobs=n_jobs, cv=kf)\n",
    "                gs_rms = GridSearchCV(clf, grid_params, scoring=rms, n_jobs=n_jobs, cv=kf)\n",
    "                \n",
    "                gs_acc.fit(X_val, y_val)\n",
    "                gs_auc.fit(X_val, y_val)\n",
    "                gs_rms.fit(X_val, y_val)\n",
    "\n",
    "                result_tuning[\"gs_acc\"] = {}\n",
    "                result_tuning[\"gs_acc\"][\"best_params\"] = gs_acc.best_params_\n",
    "                result_tuning[\"gs_acc\"][\"grid_scores\"] = gs_acc.grid_scores_\n",
    "                \n",
    "                result_tuning[\"gs_auc\"] = {}\n",
    "                result_tuning[\"gs_auc\"][\"best_params\"] = gs_auc.best_params_\n",
    "                result_tuning[\"gs_auc\"][\"grid_scores\"] = gs_auc.grid_scores_\n",
    "                \n",
    "                result_tuning[\"gs_rms\"] = {}\n",
    "                result_tuning[\"gs_rms\"][\"best_params\"] = gs_rms.best_params_\n",
    "                result_tuning[\"gs_rms\"][\"grid_scores\"] = gs_rms.grid_scores_  \n",
    "                \n",
    "                with open(no_fs_path + \"/result_tuning.txt\", 'wb') as fp:\n",
    "                    pickle.dump(result_tuning, fp)\n",
    "               \n",
    "            elif fs and (data_name in big_data):\n",
    "                result_tuning[\"feature_selection\"] = fs\n",
    "                X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=tuning_seed, stratify=y)\n",
    "                X_val = X_val.iloc[:, best_features[:100]]\n",
    "                fs_path = data_path + '/' + \"FS\"\n",
    "                if \"FS\" not in os.listdir(data_path):\n",
    "                    os.mkdir(fs_path)                \n",
    "                \n",
    "                gs_seed = 1\n",
    "                result_tuning[\"gs_seed\"] = gs_seed\n",
    "                \n",
    "                kf = StratifiedKFold(y_val, n_folds=3, shuffle=True, random_state=gs_seed)\n",
    "                \n",
    "                n_jobs = 1\n",
    "\n",
    "                grid_params = load_grid_parameters(clf_name)\n",
    "                    \n",
    "                gs_acc = GridSearchCV(clf, grid_params, scoring=\"accuracy\", n_jobs=n_jobs, cv=kf)\n",
    "                gs_auc = GridSearchCV(clf, grid_params, scoring=\"roc_auc\", n_jobs=n_jobs, cv=kf)\n",
    "                gs_rms = GridSearchCV(clf, grid_params, scoring=rms, n_jobs=n_jobs, cv=kf)\n",
    "                \n",
    "                gs_acc.fit(X_val, y_val)\n",
    "                gs_auc.fit(X_val, y_val)\n",
    "                gs_rms.fit(X_val, y_val)\n",
    "                \n",
    "                ### GRID SEARCH ###\n",
    "                result_tuning[\"gs_acc\"] = {}\n",
    "                result_tuning[\"gs_acc\"][\"best_params\"] = gs_acc.best_params_\n",
    "                result_tuning[\"gs_acc\"][\"grid_scores\"] = gs_acc.grid_scores_\n",
    "                \n",
    "                result_tuning[\"gs_auc\"] = {}\n",
    "                result_tuning[\"gs_auc\"][\"best_params\"] = gs_auc.best_params_\n",
    "                result_tuning[\"gs_auc\"][\"grid_scores\"] = gs_auc.grid_scores_\n",
    "                \n",
    "                result_tuning[\"gs_rms\"] = {}\n",
    "                result_tuning[\"gs_rms\"][\"best_params\"] = gs_rms.best_params_\n",
    "                result_tuning[\"gs_rms\"][\"grid_scores\"] = gs_rms.grid_scores_      \n",
    "                \n",
    "                with open(fs_path + \"/result_tuning.txt\", 'wb') as fp:\n",
    "                    pickle.dump(result_tuning, fp)                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
